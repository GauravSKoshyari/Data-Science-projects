{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfZo8fmLOec"
      },
      "source": [
        "## Task -1: Simple Encoder and Decoder\n",
        "Implement simple Encoder-Decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNSZXNkkOkO"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data this way only: \n",
        "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
        "    \n",
        "3. You have to implement a simple Encoder and Decoder architecture  \n",
        "\n",
        "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "6.  a. Check the reference notebook <br>\n",
        "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_gldAAiO5e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd6eda38-bf44-482f-ce8e-1d57ff273811"
      },
      "source": [
        "!wget --header=\"Host: www.manythings.org\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.54 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7\" --header=\"Cookie: __utma=3028652.1607358814.1634216631.1634216631.1634216631.1; __utmz=3028652.1634216631.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none)\" --header=\"Connection: keep-alive\" \"http://www.manythings.org/anki/ita-eng.zip\" -c -O 'ita-eng.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-27 14:14:49--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7782544 (7.4M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   7.42M  19.4MB/s    in 0.4s    \n",
            "\n",
            "2022-08-27 14:14:49 (19.4 MB/s) - ‘ita-eng.zip’ saved [7782544/7782544]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e_2k8Q0PDb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f021e787-5e89-4cdb-9d4c-3d428ef30016"
      },
      "source": [
        "!unzip ita-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KHw1l6QREOD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "d5f77e44-1eb0-4098-f4ae-4ad5ece81e59",
        "id": "TW1BV13OweHd"
      },
      "source": [
        "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])\n",
        "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(354238, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1     Hi.     Ciao.\n",
              "2    Run!    Corri!\n",
              "3    Run!    Corra!\n",
              "4    Run!  Correte!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-badb452b-b784-4a50-8c09-58c4f8155406\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-badb452b-b784-4a50-8c09-58c4f8155406')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-badb452b-b784-4a50-8c09-58c4f8155406 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-badb452b-b784-4a50-8c09-58c4f8155406');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnDyE0ljbYor",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "777477dc-d159-4204-94a7-9f616bac7202"
      },
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['english'] = data['english'].apply(preprocess)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6af47a6-1daf-4390-8fd1-cf2b4f1e90aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6af47a6-1daf-4390-8fd1-cf2b4f1e90aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6af47a6-1daf-4390-8fd1-cf2b4f1e90aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6af47a6-1daf-4390-8fd1-cf2b4f1e90aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IypVGvYKREOL"
      },
      "source": [
        "ita_lengths = data['italian'].str.split().apply(len)\n",
        "eng_lengths = data['english'].str.split().apply(len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOWJ9c5jREON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8ead81-7b83-440a-a7ac-01796507b6c7"
      },
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(ita_lengths, i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 3.0\n",
            "20 4.0\n",
            "30 4.0\n",
            "40 5.0\n",
            "50 5.0\n",
            "60 6.0\n",
            "70 6.0\n",
            "80 7.0\n",
            "90 8.0\n",
            "100 92.0\n",
            "90 8.0\n",
            "91 8.0\n",
            "92 8.0\n",
            "93 9.0\n",
            "94 9.0\n",
            "95 9.0\n",
            "96 9.0\n",
            "97 10.0\n",
            "98 11.0\n",
            "99 12.0\n",
            "100 92.0\n",
            "99.1 12.0\n",
            "99.2 12.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 13.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 22.0\n",
            "100 92.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGCOWtN1REOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9078a2-05aa-4418-cddc-569cc2e9ca25"
      },
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(eng_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(eng_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(eng_lengths, i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 4.0\n",
            "20 4.0\n",
            "30 5.0\n",
            "40 5.0\n",
            "50 6.0\n",
            "60 6.0\n",
            "70 7.0\n",
            "80 7.0\n",
            "90 8.0\n",
            "100 101.0\n",
            "90 8.0\n",
            "91 9.0\n",
            "92 9.0\n",
            "93 9.0\n",
            "94 9.0\n",
            "95 9.0\n",
            "96 10.0\n",
            "97 10.0\n",
            "98 11.0\n",
            "99 12.0\n",
            "100 101.0\n",
            "99.1 12.0\n",
            "99.2 13.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 14.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 25.0\n",
            "100 101.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-6pcMyuREOR"
      },
      "source": [
        "> <font color=\"blue\"><b>If you observe the values, 99.9% of the data points are having length &lt; 22 for italian sentences and  &lt; 25 for english sentences  </b> </font>\n",
        "<br>\n",
        "<br>\n",
        "> <font color=\"green\"><b>Inorder to do the teacher forcing while training of seq-seq models, lets create two new columns, one with  &lt;start&gt; token at begining of the sentence and other column with &lt;end&gt; token at the end of the sequence</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frL1wvLwSz7_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "1158e2ec-f03f-42bf-e8b5-674ef106f564"
      },
      "source": [
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 22]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 25]\n",
        "\n",
        "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
        "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
        "\n",
        "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   italian  english_inp english_out\n",
              "0     ciao   <start> hi    hi <end>\n",
              "1     ciao   <start> hi    hi <end>\n",
              "2    corri  <start> run   run <end>\n",
              "3    corra  <start> run   run <end>\n",
              "4  correte  <start> run   run <end>"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ec985ff-3f10-4b20-9309-0fca4eea8b6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ec985ff-3f10-4b20-9309-0fca4eea8b6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ec985ff-3f10-4b20-9309-0fca4eea8b6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ec985ff-3f10-4b20-9309-0fca4eea8b6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZX5xAcmxqPo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "6ee907d8-54bb-41ae-82d4-b9ff8316876e"
      },
      "source": [
        "data.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  italian  \\\n",
              "306085   non cè nessuna possibilità che lui si riprenderà   \n",
              "279836                          cercai il libro per unora   \n",
              "13943                                      io sono devota   \n",
              "127274                                    tom è vivo vero   \n",
              "245448           pensavo che noi fossimo le benvenute qui   \n",
              "353318  in questo corso passeremo del tempo aiutandola...   \n",
              "228681                         siete mai stati in america   \n",
              "338075  tom non lo sapeva che mary si stava vedendo co...   \n",
              "235757             tom ha consigliato a mary di non farla   \n",
              "273349                      tom non vuole lasciare boston   \n",
              "\n",
              "                                              english_inp  \\\n",
              "306085    <start> there is no chance that he will recover   \n",
              "279836          <start> i looked for the book for an hour   \n",
              "13943                              <start> i am committed   \n",
              "127274                     <start> tom is alive is not he   \n",
              "245448             <start> i thought we were welcome here   \n",
              "353318  <start> in this course we will spend time help...   \n",
              "228681              <start> have you ever been to america   \n",
              "338075  <start> tom did not know mary was seeing someo...   \n",
              "235757              <start> tom advised mary not to do it   \n",
              "273349          <start> tom does not want to leave boston   \n",
              "\n",
              "                                              english_out  \n",
              "306085      there is no chance that he will recover <end>  \n",
              "279836            i looked for the book for an hour <end>  \n",
              "13943                                i am committed <end>  \n",
              "127274                       tom is alive is not he <end>  \n",
              "245448               i thought we were welcome here <end>  \n",
              "353318  in this course we will spend time helping you ...  \n",
              "228681                have you ever been to america <end>  \n",
              "338075  tom did not know mary was seeing someone else ...  \n",
              "235757                tom advised mary not to do it <end>  \n",
              "273349            tom does not want to leave boston <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cf8f467-ef4a-4cd4-8f2d-622625f0a506\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>306085</th>\n",
              "      <td>non cè nessuna possibilità che lui si riprenderà</td>\n",
              "      <td>&lt;start&gt; there is no chance that he will recover</td>\n",
              "      <td>there is no chance that he will recover &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279836</th>\n",
              "      <td>cercai il libro per unora</td>\n",
              "      <td>&lt;start&gt; i looked for the book for an hour</td>\n",
              "      <td>i looked for the book for an hour &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13943</th>\n",
              "      <td>io sono devota</td>\n",
              "      <td>&lt;start&gt; i am committed</td>\n",
              "      <td>i am committed &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127274</th>\n",
              "      <td>tom è vivo vero</td>\n",
              "      <td>&lt;start&gt; tom is alive is not he</td>\n",
              "      <td>tom is alive is not he &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245448</th>\n",
              "      <td>pensavo che noi fossimo le benvenute qui</td>\n",
              "      <td>&lt;start&gt; i thought we were welcome here</td>\n",
              "      <td>i thought we were welcome here &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353318</th>\n",
              "      <td>in questo corso passeremo del tempo aiutandola...</td>\n",
              "      <td>&lt;start&gt; in this course we will spend time help...</td>\n",
              "      <td>in this course we will spend time helping you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228681</th>\n",
              "      <td>siete mai stati in america</td>\n",
              "      <td>&lt;start&gt; have you ever been to america</td>\n",
              "      <td>have you ever been to america &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338075</th>\n",
              "      <td>tom non lo sapeva che mary si stava vedendo co...</td>\n",
              "      <td>&lt;start&gt; tom did not know mary was seeing someo...</td>\n",
              "      <td>tom did not know mary was seeing someone else ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235757</th>\n",
              "      <td>tom ha consigliato a mary di non farla</td>\n",
              "      <td>&lt;start&gt; tom advised mary not to do it</td>\n",
              "      <td>tom advised mary not to do it &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273349</th>\n",
              "      <td>tom non vuole lasciare boston</td>\n",
              "      <td>&lt;start&gt; tom does not want to leave boston</td>\n",
              "      <td>tom does not want to leave boston &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cf8f467-ef4a-4cd4-8f2d-622625f0a506')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cf8f467-ef4a-4cd4-8f2d-622625f0a506 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cf8f467-ef4a-4cd4-8f2d-622625f0a506');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting train and test \n"
      ],
      "metadata": {
        "id": "YDKhHB7Ex_uu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG50P52vhMu8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data, test_size=0.2 , random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape, validation.shape)\n",
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
        "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzKdeCl8DigJ",
        "outputId": "c187a4c5-3db5-4124-f662-c766745165c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(283068, 3) (70767, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su69ZPzTsxmn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1734afdb-839a-4407-8692-9f1930da8e95"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   italian  \\\n",
              "122627    ci vedremo la settimana prossima   \n",
              "130538        chi le ha dato questo elenco   \n",
              "161415  dobbiamo andarcene da questo posto   \n",
              "207536       tom sta guardando un film ora   \n",
              "102547              non si scordi la borsa   \n",
              "\n",
              "                                   english_inp  \\\n",
              "122627  <start> i will see you next week <end>   \n",
              "130538          <start> who gave you this list   \n",
              "161415        <start> we must leave this place   \n",
              "207536     <start> tom is watching a movie now   \n",
              "102547          <start> do not forget your bag   \n",
              "\n",
              "                                 english_out  \n",
              "122627  i will see you next week <end> <end>  \n",
              "130538          who gave you this list <end>  \n",
              "161415        we must leave this place <end>  \n",
              "207536     tom is watching a movie now <end>  \n",
              "102547          do not forget your bag <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e18c177-c4ef-4903-a628-b71586a5a265\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>122627</th>\n",
              "      <td>ci vedremo la settimana prossima</td>\n",
              "      <td>&lt;start&gt; i will see you next week &lt;end&gt;</td>\n",
              "      <td>i will see you next week &lt;end&gt; &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130538</th>\n",
              "      <td>chi le ha dato questo elenco</td>\n",
              "      <td>&lt;start&gt; who gave you this list</td>\n",
              "      <td>who gave you this list &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161415</th>\n",
              "      <td>dobbiamo andarcene da questo posto</td>\n",
              "      <td>&lt;start&gt; we must leave this place</td>\n",
              "      <td>we must leave this place &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207536</th>\n",
              "      <td>tom sta guardando un film ora</td>\n",
              "      <td>&lt;start&gt; tom is watching a movie now</td>\n",
              "      <td>tom is watching a movie now &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102547</th>\n",
              "      <td>non si scordi la borsa</td>\n",
              "      <td>&lt;start&gt; do not forget your bag</td>\n",
              "      <td>do not forget your bag &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e18c177-c4ef-4903-a628-b71586a5a265')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e18c177-c4ef-4903-a628-b71586a5a265 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e18c177-c4ef-4903-a628-b71586a5a265');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGqQDR8FWV3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "35d42e82-66d6-4fd0-8363-3a079edb5d6f"
      },
      "source": [
        "validation.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          italian  \\\n",
              "144180      tom rimase a casa per tutto il giorno   \n",
              "120500                    io dovevo dire qualcosa   \n",
              "137797                       voglio sbarazzarmene   \n",
              "78480                         oggi cè molto caldo   \n",
              "320129  disse al suo assistente che avrebbe vinto   \n",
              "\n",
              "                                            english_inp  \\\n",
              "144180                  <start> tom stayed home all day   \n",
              "120500                   <start> i had to say something   \n",
              "137797                  <start> i want to get rid of it   \n",
              "78480                      <start> it is very hot today   \n",
              "320129  <start> he told his assistant that he would win   \n",
              "\n",
              "                                          english_out  \n",
              "144180                  tom stayed home all day <end>  \n",
              "120500                   i had to say something <end>  \n",
              "137797                  i want to get rid of it <end>  \n",
              "78480                      it is very hot today <end>  \n",
              "320129  he told his assistant that he would win <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1e86175-9a92-4d32-b5f1-1506a8069d76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144180</th>\n",
              "      <td>tom rimase a casa per tutto il giorno</td>\n",
              "      <td>&lt;start&gt; tom stayed home all day</td>\n",
              "      <td>tom stayed home all day &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120500</th>\n",
              "      <td>io dovevo dire qualcosa</td>\n",
              "      <td>&lt;start&gt; i had to say something</td>\n",
              "      <td>i had to say something &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137797</th>\n",
              "      <td>voglio sbarazzarmene</td>\n",
              "      <td>&lt;start&gt; i want to get rid of it</td>\n",
              "      <td>i want to get rid of it &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78480</th>\n",
              "      <td>oggi cè molto caldo</td>\n",
              "      <td>&lt;start&gt; it is very hot today</td>\n",
              "      <td>it is very hot today &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320129</th>\n",
              "      <td>disse al suo assistente che avrebbe vinto</td>\n",
              "      <td>&lt;start&gt; he told his assistant that he would win</td>\n",
              "      <td>he told his assistant that he would win &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1e86175-9a92-4d32-b5f1-1506a8069d76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1e86175-9a92-4d32-b5f1-1506a8069d76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1e86175-9a92-4d32-b5f1-1506a8069d76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpuPONunjYKj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "75a1d288-2005-4784-89e3-5828575f4ee0"
      },
      "source": [
        "ita_lengths = train['italian'].str.split().apply(len)\n",
        "eng_lengths = train['english_inp'].str.split().apply(len)\n",
        "import seaborn as sns\n",
        "sns.kdeplot(ita_lengths)\n",
        "plt.show()\n",
        "sns.kdeplot(eng_lengths)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msOiI69-REOi"
      },
      "source": [
        "### Creating Tokenizer on the train data and learning vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7xUCLf6REOi"
      },
      "source": [
        "> Note that we are fitting the tokenizer only on train data and check the filters for english, we need to remove symbols &lt; and &gt;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPa0ldDWkav8"
      },
      "source": [
        "tknizer_ita = Tokenizer()\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBb0yEYlCynz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc08a40d-ee54-4f3a-910e-6bf3f2ab4723"
      },
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(vocab_size_ita)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13086\n",
            "26775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm1uoAC-Nwuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567a4ba0-73a0-416f-cd8f-19ddaec2e478"
      },
      "source": [
        "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10327)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_eng.index_word[2]\n",
        "# tknizer_eng.index_word[0]                         # key error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xmLJIYezzIf2",
        "outputId": "dd19a5db-87b6-43a8-8c69-734a37c34b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT2R3D6MREOp"
      },
      "source": [
        "### Creating embeddings for english sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n"
      ],
      "metadata": {
        "id": "mixHkLFBywaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9705a52-ea9d-4eb6-d4e2-26edaf6989f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-27 14:15:25--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
            "--2022-08-27 14:15:25--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucfd3a094e8b680a2539779619f3.dl.dropboxusercontent.com/cd/0/inline/Bry8dzxtqE4BdgZVJgE1BEFsw0k03WJraVArucdQ57mOt6rrHZHuABIfIGp0EvHh8hZXAxzL_6iyLW66yDgFLW_zzFHZWO2CMqwQKC5YCWDPirpCOpOsH98YlwP3_ATO83EQZhGyhEmcGiAxic6CimJ4gcCCYDOb63qxDNmpzjcENg/file# [following]\n",
            "--2022-08-27 14:15:25--  https://ucfd3a094e8b680a2539779619f3.dl.dropboxusercontent.com/cd/0/inline/Bry8dzxtqE4BdgZVJgE1BEFsw0k03WJraVArucdQ57mOt6rrHZHuABIfIGp0EvHh8hZXAxzL_6iyLW66yDgFLW_zzFHZWO2CMqwQKC5YCWDPirpCOpOsH98YlwP3_ATO83EQZhGyhEmcGiAxic6CimJ4gcCCYDOb63qxDNmpzjcENg/file\n",
            "Resolving ucfd3a094e8b680a2539779619f3.dl.dropboxusercontent.com (ucfd3a094e8b680a2539779619f3.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6019:15::a27d:40f\n",
            "Connecting to ucfd3a094e8b680a2539779619f3.dl.dropboxusercontent.com (ucfd3a094e8b680a2539779619f3.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘glove.6B.100d.txt’\n",
            "\n",
            "glove.6B.100d.txt   100%[===================>] 331.04M   117MB/s    in 2.8s    \n",
            "\n",
            "2022-08-27 14:15:28 (117 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olaKF9rb_zz1"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
        "for word, i in tknizer_eng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_eng.word_index['<end>'] , tknizer_eng.word_index['<start>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t7CPbbEfMgj",
        "outputId": "6f6f4d63-41ab-4fe7-eeae-591a75cc2255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10327, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix[10327]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x-wdW4afQ5l",
        "outputId": "22197845-f380-471c-a22b-00a914d346aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IisCHvFcfdF1",
        "outputId": "876e4a39-2d24-48be-d57f-b0266d0d683f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)\n",
        "embedding_matrix[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA-hwvS7zv8t",
        "outputId": "c0f77762-f876-414f-d074-ee6fdf6a9c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13087, 100)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqCTPT5JxYvH"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "tf.keras.backend.clear_session()\n",
        "from tensorflow.keras.layers import Input, Softmax, RNN, Dense, Embedding, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cex2XfCLOew"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,vocab_size,embedding_dim,enc_units,input_length):\n",
        "      super().__init__()\n",
        "      self.vocab_size = vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.enc_units = enc_units\n",
        "      self.input_length = input_length\n",
        "      self.encoder_outputs =0\n",
        "      self.encoder_final_state_h = 0\n",
        "      self.encoder_final_state_c = 0 \n",
        "\n",
        "      #Initialize Embedding layer\n",
        "      self.embedding = Embedding(input_dim=self.vocab_size , output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")    \n",
        "\n",
        "      #Intialize Encoder LSTM layer\n",
        "      self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sentence,states):\n",
        "      input_embedd = self.embedding(input_sentence)\n",
        "      self.encoder_outputs , self.encoder_final_state_h , self.encoder_final_state_c = self.lstm(input_embedd , initial_state = states)\n",
        "      return self.encoder_outputs , self.encoder_final_state_h , self.encoder_final_state_c\n",
        "      '''\n",
        "        This function takes a sequence input and the initial states of the encoder.\n",
        "        Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "        returns -- encoder_output, last time step's hidden and cell state\n",
        "      '''\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      return tf.zeros([batch_size , self.enc_units]) , tf.zeros([batch_size , self.enc_units])\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziSqOgmhLOe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1673c35a-9ba6-4868-aa0c-bd02ee88d9d2"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ES1-sJLOe4"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "      super().__init__()\n",
        "      self.dec_vocab_size = out_vocab_size\n",
        "      self.embedding_size = embedding_size\n",
        "      self.lstm_size = lstm_size\n",
        "      self.input_length = input_length\n",
        "      self.decoder_outputs =0\n",
        "      self.decoder_final_state_h = 0\n",
        "      self.decoder_final_state_c = 0 \n",
        "\n",
        "      #Initialize Embedding layer\n",
        "      self.embedding = Embedding(input_dim=self.dec_vocab_size , output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\" ,weights=[embedding_matrix], trainable=False )   \n",
        "    #   self.embedding = Embedding(input_dim=self.dec_vocab_size , output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                        #    mask_zero=True, name=\"embedding_layer_encoder\"  )    \n",
        "\n",
        "      #Intialize Decoder LSTM layer\n",
        "      self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n",
        "      \n",
        "    def call(self,input_sequence,initial_states):\n",
        "      target_embedd = self.embedding(input_sequence)\n",
        "      self.decoder_outputs , self.decoder_final_state_h , self.decoder_final_state_c = self.lstm(target_embedd , initial_state = initial_states)\n",
        "      return self.decoder_outputs , self.decoder_final_state_h , self.decoder_final_state_c\n",
        "      '''\n",
        "        This function takes a sequence input and the initial states of the encoder.\n",
        "        Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "      \n",
        "        returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "      '''\n",
        "\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B0gokgKLOe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00d3d58-020b-485d-c6b2-403455dd3553"
      },
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXrIj4scLOe_"
      },
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,encoder_inputs_length,decoder_inputs_length):\n",
        "        super().__init__()\n",
        "        #Create encoder object\n",
        "        self.encoder = Encoder(vocab_size = vocab_size_ita+1 ,embedding_dim =100 , enc_units = 100 ,input_length = encoder_inputs_length)        #  +1  is for  0 \n",
        "        #Create decoder object\n",
        "        self.decoder = Decoder(out_vocab_size = vocab_size_eng + 1 ,embedding_size = 100,lstm_size = 100,input_length = decoder_inputs_length)\n",
        "\n",
        "        self.dense=Dense(vocab_size_eng ,activation='softmax'  )\n",
        "    \n",
        "\n",
        "    def call(self,data):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer \n",
        "        \n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        input,output = data[0], data[1]\n",
        "        enc_initial_states = self.encoder.initialize_states(1024)\n",
        "        encoder_output, encoder_final_state_h,encoder_final_state_c = self.encoder(input , enc_initial_states)\n",
        "        initial_states = [ encoder_final_state_h,encoder_final_state_c]\n",
        "        decoder_output , _ , _  = self.decoder(output,initial_states)\n",
        "        output  = self.dense(decoder_output)\n",
        "        return output\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmB27pW_7MoX"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mBXRd_sus3C"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len_ita , max_len_eng):\n",
        "        self.encoder_inps = data['italian'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len_ita = max_len_ita\n",
        "        self.max_len_eng = max_len_eng\n",
        "\n",
        "    def __getitem__(self, i):                                         \n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len_ita, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len_eng, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len_eng, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])                 #  three things will be appended\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDKh6iikRUyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467f61ee-1688-49d1-a3d2-2ac568b77914"
      },
      "source": [
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 22 , 25 )\n",
        "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 22, 25)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=1024)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=1024)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024, 22) (1024, 25) (1024, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "0p9aVYlHGr-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcL61dJXLOfB"
      },
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model\n",
        "\n",
        "model  = Encoder_decoder(encoder_inputs_length=22,decoder_inputs_length=25)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer,loss=loss_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min'  ,restore_best_weights = True \n",
        ")"
      ],
      "metadata": {
        "id": "KDYEGJIqGZNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50, validation_data=test_dataloader, validation_steps=valid_steps , callbacks = [earlystop])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9ywezpsDEQC",
        "outputId": "77106f9a-5a59-455a-ba98-93f8aca5fb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "276/276 [==============================] - 67s 223ms/step - loss: 0.6251 - val_loss: 0.5936\n",
            "Epoch 2/50\n",
            "276/276 [==============================] - 60s 218ms/step - loss: 0.5811 - val_loss: 0.5601\n",
            "Epoch 3/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.5471 - val_loss: 0.5257\n",
            "Epoch 4/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.5123 - val_loss: 0.4916\n",
            "Epoch 5/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.4782 - val_loss: 0.4575\n",
            "Epoch 6/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.4439 - val_loss: 0.4239\n",
            "Epoch 7/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.4100 - val_loss: 0.3902\n",
            "Epoch 8/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.3761 - val_loss: 0.3569\n",
            "Epoch 9/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.3426 - val_loss: 0.3238\n",
            "Epoch 10/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.3095 - val_loss: 0.2916\n",
            "Epoch 11/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.2773 - val_loss: 0.2602\n",
            "Epoch 12/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.2460 - val_loss: 0.2297\n",
            "Epoch 13/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.2157 - val_loss: 0.2004\n",
            "Epoch 14/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.1866 - val_loss: 0.1725\n",
            "Epoch 15/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.1595 - val_loss: 0.1470\n",
            "Epoch 16/50\n",
            "276/276 [==============================] - 59s 212ms/step - loss: 0.1350 - val_loss: 0.1244\n",
            "Epoch 17/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.1137 - val_loss: 0.1051\n",
            "Epoch 18/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0959 - val_loss: 0.0893\n",
            "Epoch 19/50\n",
            "276/276 [==============================] - 59s 215ms/step - loss: 0.0815 - val_loss: 0.0769\n",
            "Epoch 20/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0701 - val_loss: 0.0671\n",
            "Epoch 21/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0612 - val_loss: 0.0594\n",
            "Epoch 22/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0542 - val_loss: 0.0535\n",
            "Epoch 23/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0486 - val_loss: 0.0488\n",
            "Epoch 24/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0441 - val_loss: 0.0449\n",
            "Epoch 25/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0404 - val_loss: 0.0418\n",
            "Epoch 26/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0373 - val_loss: 0.0392\n",
            "Epoch 27/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0348 - val_loss: 0.0370\n",
            "Epoch 28/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0325 - val_loss: 0.0352\n",
            "Epoch 29/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0306 - val_loss: 0.0336\n",
            "Epoch 30/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0290 - val_loss: 0.0322\n",
            "Epoch 31/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0275 - val_loss: 0.0310\n",
            "Epoch 32/50\n",
            "276/276 [==============================] - 59s 215ms/step - loss: 0.0262 - val_loss: 0.0301\n",
            "Epoch 33/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0250 - val_loss: 0.0291\n",
            "Epoch 34/50\n",
            "276/276 [==============================] - 61s 221ms/step - loss: 0.0240 - val_loss: 0.0283\n",
            "Epoch 35/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0230 - val_loss: 0.0275\n",
            "Epoch 36/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0222 - val_loss: 0.0269\n",
            "Epoch 37/50\n",
            "276/276 [==============================] - 59s 213ms/step - loss: 0.0214 - val_loss: 0.0263\n",
            "Epoch 38/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0207 - val_loss: 0.0257\n",
            "Epoch 39/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0200 - val_loss: 0.0252\n",
            "Epoch 40/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0193 - val_loss: 0.0247\n",
            "Epoch 41/50\n",
            "276/276 [==============================] - 65s 233ms/step - loss: 0.0187 - val_loss: 0.0243\n",
            "Epoch 42/50\n",
            "276/276 [==============================] - 60s 215ms/step - loss: 0.0182 - val_loss: 0.0239\n",
            "Epoch 43/50\n",
            "276/276 [==============================] - 65s 234ms/step - loss: 0.0177 - val_loss: 0.0236\n",
            "Epoch 44/50\n",
            "276/276 [==============================] - 60s 217ms/step - loss: 0.0172 - val_loss: 0.0233\n",
            "Epoch 45/50\n",
            "276/276 [==============================] - 60s 218ms/step - loss: 0.0167 - val_loss: 0.0230\n",
            "Epoch 46/50\n",
            "276/276 [==============================] - 62s 224ms/step - loss: 0.0163 - val_loss: 0.0227\n",
            "Epoch 47/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0159 - val_loss: 0.0224\n",
            "Epoch 48/50\n",
            "276/276 [==============================] - 59s 215ms/step - loss: 0.0155 - val_loss: 0.0222\n",
            "Epoch 49/50\n",
            "276/276 [==============================] - 59s 215ms/step - loss: 0.0152 - val_loss: 0.0219\n",
            "Epoch 50/50\n",
            "276/276 [==============================] - 59s 214ms/step - loss: 0.0148 - val_loss: 0.0217\n",
            "Model: \"encoder_decoder_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         multiple                  2758000   \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  1389100   \n",
            "                                                                 \n",
            " dense_5 (Dense)             multiple                  1321686   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,468,786\n",
            "Trainable params: 4,160,086\n",
            "Non-trainable params: 1,308,700\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb6S6iz0UnUo"
      },
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "\n",
        "  predicted_sentence = \"\"\n",
        "  # sequence_ita = tknizer_ita.texts_to_sequences([validation.iloc[0]['italian']])\n",
        "  sequence_ita = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  seq_emb = model.layers[0].embedding(np.array(sequence_ita))                         # (1, encoder_input_length,  enc_embedding_dim)\n",
        "  encoder_outputs , last_h_state , last_c_state =   model.layers[0].lstm(seq_emb)      # encoder_outputs  -> (1, encoder_input_length , enc_lstm_units)\n",
        "  initial_states = [last_h_state , last_c_state]                        # last_h_state  -> (1,  enc_lstm_units)\n",
        " \n",
        "  \n",
        "  input_dec = tknizer_eng.word_index['<start>']\n",
        "  word_index_end = tknizer_eng.word_index['<end>']\n",
        "\n",
        "  for i in range(25):\n",
        "    # print(i)\n",
        "    dec_inp_emb = model.layers[1].embedding(np.reshape(input_dec , (1,1)))                    # (1,1,100)\n",
        "    dec_output  , state_h , state_c = model.layers[1].lstm(dec_inp_emb , initial_state = initial_states)          # dec_output -> (1, 1, dec_lstm_units)\n",
        "    dec_output_final = model.layers[2](dec_output)                            # (1, 1, 13086)\n",
        "\n",
        "    initial_states = [state_h , state_c]\n",
        "    input_dec = np.argmax(dec_output_final)              # natural no \n",
        "\n",
        "    # print(tknizer_eng.index_word[input_dec] , input_dec)\n",
        "\n",
        "    if input_dec == word_index_end:                 \n",
        "      break\n",
        "    predicted_sentence += \" \" + tknizer_eng.index_word[input_dec]\n",
        "\n",
        "    # print(predicted_sentence)\n",
        "\n",
        "  return str.strip(predicted_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tknizer_eng.index_word[1])\n",
        "tknizer_eng.index_word[13086]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lkcTv-EMtwDW",
        "outputId": "c56d5649-e3d4-4c03-d00c-5deffedd22c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'250000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "italian_10 = validation.head(10)['italian']\n",
        "original_english_10 = validation.head(10)['english_out']\n",
        "predicted_sentence_10 = []\n",
        "\n",
        "for italian in italian_10:\n",
        "  predicted_sentence_10.append(predict(italian))\n",
        "\n",
        "result_10 = pd.DataFrame({'original' : original_english_10 , 'predicted' : predicted_sentence_10})\n",
        "result_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SdGPw8m7RU_q",
        "outputId": "767c874b-771c-4c18-baae-3946df3c7d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             original  \\\n",
              "144180                  tom stayed home all day <end>   \n",
              "120500                   i had to say something <end>   \n",
              "137797                  i want to get rid of it <end>   \n",
              "78480                      it is very hot today <end>   \n",
              "320129  he told his assistant that he would win <end>   \n",
              "218316            i am not one of your soldiers <end>   \n",
              "316039   i knew it would happen sooner or later <end>   \n",
              "106906                i would like to go faster <end>   \n",
              "317803   things are getting out of control here <end>   \n",
              "28335                          i am not worried <end>   \n",
              "\n",
              "                                       predicted  \n",
              "144180                   tom stayed home all day  \n",
              "120500                    i had to say something  \n",
              "137797                   i want to get rid of it  \n",
              "78480                    is there very hot today  \n",
              "320129        he told her assistant he would win  \n",
              "218316              i am not one of the painting  \n",
              "316039  i knew you would like to the same sooner  \n",
              "106906                 i would like to go faster  \n",
              "317803       things are getting out of going out  \n",
              "28335                           i am not worried  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60dea1d4-6c9b-4bfc-b58e-7fe6f2bdfd14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144180</th>\n",
              "      <td>tom stayed home all day &lt;end&gt;</td>\n",
              "      <td>tom stayed home all day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120500</th>\n",
              "      <td>i had to say something &lt;end&gt;</td>\n",
              "      <td>i had to say something</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137797</th>\n",
              "      <td>i want to get rid of it &lt;end&gt;</td>\n",
              "      <td>i want to get rid of it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78480</th>\n",
              "      <td>it is very hot today &lt;end&gt;</td>\n",
              "      <td>is there very hot today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320129</th>\n",
              "      <td>he told his assistant that he would win &lt;end&gt;</td>\n",
              "      <td>he told her assistant he would win</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218316</th>\n",
              "      <td>i am not one of your soldiers &lt;end&gt;</td>\n",
              "      <td>i am not one of the painting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316039</th>\n",
              "      <td>i knew it would happen sooner or later &lt;end&gt;</td>\n",
              "      <td>i knew you would like to the same sooner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106906</th>\n",
              "      <td>i would like to go faster &lt;end&gt;</td>\n",
              "      <td>i would like to go faster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317803</th>\n",
              "      <td>things are getting out of control here &lt;end&gt;</td>\n",
              "      <td>things are getting out of going out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28335</th>\n",
              "      <td>i am not worried &lt;end&gt;</td>\n",
              "      <td>i am not worried</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60dea1d4-6c9b-4bfc-b58e-7fe6f2bdfd14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60dea1d4-6c9b-4bfc-b58e-7fe6f2bdfd14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60dea1d4-6c9b-4bfc-b58e-7fe6f2bdfd14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "\n",
        "eng_original = [['she', 'has', 'brought', 'up', 'five', 'children']]\n",
        "eng_predict = ['she', 'brought', 'up', 'two', 'children']\n",
        "\n",
        "print(bleu.sentence_bleu(eng_original, eng_predict , weights=(0.5,0.5) ) )        # evaluating translations upto 2-grams with uniform weights\n",
        "print(bleu.sentence_bleu(eng_original, eng_predict , weights=(1.0 ,) )    )     # evaluating translations upto 1-grams with uniform weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCiVvPbWKvSp",
        "outputId": "5d09a4c9-40ca-46dd-e1eb-e236b4dd017e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3661475238303926\n",
            "0.6549846024623855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_original = [['i', 'at', 'am', 'the', 'hospital', 'now']]\n",
        "eng_predict = ['i', 'am', 'at', 'the', 'hospital', 'now']\n",
        "bleu.sentence_bleu(eng_original, eng_predict , weights=(0.5,0.5) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZkivAnsfbg6",
        "outputId": "9f8e3529-8126-4362-825e-f085bfc3cdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6324555320336759"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_original = [['i', 'at', 'am', 'the', 'hospital', 'now']]\n",
        "eng_predict = ['i', 'am', 'at', 'the', 'hospital', 'now']\n",
        "bleu.sentence_bleu(eng_original, eng_predict , weights=(1.0 , ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MfoCjcpUR_K",
        "outputId": "a3b9422c-08aa-41ca-fb13-d0f1da0708a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation['italian'].iloc[57])\n",
        "print(validation['italian'].iloc[174])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYWIkr0rrG35",
        "outputId": "edb22c03-f6e2-426f-81d9-1c5c816c7849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uccidila\n",
            "vediamolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "avg_score = 0 \n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "  if i==57 or i == 174:\n",
        "      continue\n",
        "    \n",
        "  eng_original = [validation['english_out'].iloc[i].split()[:-1] ]\n",
        "  # print(i)\n",
        "\n",
        "  italian_original = validation['italian'].iloc[i]\n",
        "  eng_predict = predict(italian_original).split()\n",
        "\n",
        "\n",
        "#   score = bleu.sentence_bleu(eng_original, eng_predict ,  weights=(0.5,0.5))        # since , sentences are small considering only 1-gram and 2-gram\n",
        "  score = bleu.sentence_bleu(eng_original, eng_predict ,  weights=(1.0,))     \n",
        "  avg_score += score   \n",
        "\n",
        "avg_score = avg_score/998"
      ],
      "metadata": {
        "id": "bFcY8AOaGXqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BLEU score for 1000 test translations: \" , avg_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxFl3z8isFPN",
        "outputId": "d83c6074-77c9-4f5d-8e1a-e3b5915e177a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score for 1000 test translations:  0.7191234824567028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx_5NA24KzRp"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.enc_vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.enc_units = lstm_size\n",
        "        self.enc_input_length = input_length\n",
        "        self.encoder_outputs =0\n",
        "        self.encoder_final_state_h = 0\n",
        "        self.encoder_final_state_c = 0 \n",
        "\n",
        "            \n",
        "        #Initialize Embedding layer\n",
        "        self.embedding = Embedding(input_dim=self.enc_vocab_size +1 , output_dim=self.embedding_size, input_length=self.enc_input_length,\n",
        "                            mask_zero=True, name=\"embedding_layer_encoder\")    \n",
        "\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "            This function takes a sequence input and the initial states of the encoder.\n",
        "            Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "            returns -- All encoder_outputs, last time steps hidden and cell state\n",
        "        '''\n",
        "        input_embedd = self.embedding(input_sequence)\n",
        "        self.encoder_outputs , self.encoder_final_state_h , self.encoder_final_state_c = self.lstm(input_embedd , initial_state = states)\n",
        "        return self.encoder_outputs , self.encoder_final_state_h , self.encoder_final_state_c\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "        '''\n",
        "        Given a batch size it will return intial hidden state and intial cell state.\n",
        "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "        '''\n",
        "        return tf.zeros([batch_size , self.enc_units]) , tf.zeros([batch_size , self.enc_units])\n",
        "\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRoe65b9LB0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8959c133-6bd3-4fa8-eb8d-cc3603922964"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab5SNdPZLlur"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "      \n",
        "\n",
        "    super().__init__()\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "    self.scoring_function = scoring_function \n",
        "\n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      pass\n",
        "    if scoring_function == 'general':\n",
        "      # Intialize variables needed for General score function here\n",
        "      self.dense   = Dense(att_units)\n",
        "\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "      self.k  = 100\n",
        "      self.dense1 = Dense(self.k)\n",
        "      self.dense2 = Dense(self.k)\n",
        "      self.dense3 = Dense(1)\n",
        "  \n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "    \n",
        "    if self.scoring_function == 'dot':\n",
        "        # Implement Dot score function here\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state , axis = 2)          #(batch_size , enc_units , 1)  or (batch_size , att_units , 1) \n",
        "        scores = tf.matmul(encoder_output , decoder_hidden_state)                        #  (batch_size ,input_length , enc_units) * (batch_size , enc_units , 1) = (batch_size, input_length , 1)\n",
        "        #you can use dot layer also , \n",
        "        \n",
        "\n",
        "\n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        hidden_state = self.dense(decoder_hidden_state)              \n",
        "        hidden_state = tf.expand_dims(hidden_state , axis = 2)        \n",
        "        scores = tf.matmul(encoder_output , hidden_state)                     \n",
        "\n",
        "\n",
        "    elif self.scoring_function == 'concat':\n",
        "        hidden_state = self.dense1(decoder_hidden_state)             # (batch_size , k)\n",
        "        hidden_state = tf.expand_dims(hidden_state , axis = 1)          #(batch_size , 1, k)  \n",
        "        output = self.dense2(encoder_output)                # (batch_size , input_legth , k)\n",
        "        scores = tf.keras.activations.tanh(tf.add(hidden_state , output))          # (batch_size , input_legth , k)\n",
        "        scores = self.dense3(scores)                          ## (batch_size , input_legth , 1)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scores , axis = 1)             # (batch_size, input_length , 1)\n",
        "\n",
        "    context_vector =  tf.matmul( tf.transpose(encoder_output , perm = [0,2,1])  , attention_weights )\n",
        "    #(batch_size ,enc_units , input_length )  * (batch_size, input_length , 1)  = (batch_size , enc_units , 1)\n",
        "\n",
        "    context_vector =  context_vector[:,:,-1]               # (batch_size , enc_units)\n",
        "\n",
        "    return context_vector , attention_weights\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transpose and matmul\n",
        "\n",
        "a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
        "a  = tf.transpose(a, perm = [0,2,1])                    #(2,3,2)      ,perm - A permutation of the dimensions of a.\n",
        "b = tf.constant(np.arange(13, 21, dtype=np.int32), shape=[2, 2, 2])\n",
        "c = tf.matmul(a, b)\n",
        "c  # `a` * `b`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuHMvRmTCupJ",
        "outputId": "6d9280b7-c3b9-47bb-d904-c4b07c5f49c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
              "array([[[ 73,  78],\n",
              "        [101, 108],\n",
              "        [129, 138]],\n",
              "\n",
              "       [[309, 326],\n",
              "        [345, 364],\n",
              "        [381, 402]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add and expand_dims\n",
        "\n",
        "x = np.arange(15).reshape(3, 5)\n",
        "print(x)\n",
        "print(\"##\"*15)\n",
        "y = np.arange(45).reshape(3, 3, 5)\n",
        "print(y)\n",
        "print(\"##\"*30)\n",
        "\n",
        "x = tf.expand_dims(x , axis = 1)\n",
        "\n",
        "tf.add(x,y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZJWg5XxFd6a",
        "outputId": "3040c7e7-651c-478b-b88f-5926a3d42a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4]\n",
            " [ 5  6  7  8  9]\n",
            " [10 11 12 13 14]]\n",
            "##############################\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]\n",
            "\n",
            " [[30 31 32 33 34]\n",
            "  [35 36 37 38 39]\n",
            "  [40 41 42 43 44]]]\n",
            "############################################################\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 5), dtype=int64, numpy=\n",
              "array([[[ 0,  2,  4,  6,  8],\n",
              "        [ 5,  7,  9, 11, 13],\n",
              "        [10, 12, 14, 16, 18]],\n",
              "\n",
              "       [[20, 22, 24, 26, 28],\n",
              "        [25, 27, 29, 31, 33],\n",
              "        [30, 32, 34, 36, 38]],\n",
              "\n",
              "       [[40, 42, 44, 46, 48],\n",
              "        [45, 47, 49, 51, 53],\n",
              "        [50, 52, 54, 56, 58]]])>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dot and matmul\n",
        "\n",
        "x = np.arange(5).reshape(1, 5, 1)\n",
        "print(x)\n",
        "y = np.arange(5, 20).reshape(1, 3, 5)\n",
        "print(y)\n",
        "\n",
        "print(\"############\")\n",
        "print(tf.keras.layers.Dot(axes=(1, 2))([x, y]))\n",
        "print(\"############\")\n",
        "\n",
        "print(tf.matmul(y,x))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpFRHFnl4ymX",
        "outputId": "81faa489-666d-4b79-d21f-c53e04eb55a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0]\n",
            "  [1]\n",
            "  [2]\n",
            "  [3]\n",
            "  [4]]]\n",
            "[[[ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]\n",
            "  [15 16 17 18 19]]]\n",
            "############\n",
            "tf.Tensor([[[ 80 130 180]]], shape=(1, 1, 3), dtype=int64)\n",
            "############\n",
            "tf.Tensor(\n",
            "[[[ 80]\n",
            "  [130]\n",
            "  [180]]], shape=(1, 3, 1), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51x50h_TLrl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fed28e-3270-42ee-ba72-119aed1e4c9f"
      },
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc8m7lmOL097"
      },
      "source": [
        "class OneStepDecoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "\n",
        "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "        super().__init__()\n",
        "        self.tar_vocab_size = tar_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.dec_units = dec_units\n",
        "        self.score_fun = score_fun\n",
        "        self.att_units = att_units\n",
        "\n",
        "        self.embedding = Embedding(input_dim= self.tar_vocab_size+1 , output_dim= self.embedding_dim , input_length= self.input_length , mask_zero = True ,weights=[embedding_matrix], trainable=False  )\n",
        "        # self.embedding = Embedding(input_dim= self.tar_vocab_size + 1 , output_dim= self.embedding_dim , input_length= self.input_length , mask_zero = True )\n",
        "        self.lstm = LSTM(self.dec_units , return_state = True , return_sequences = True)\n",
        "        self.attention = Attention(self.score_fun , self.att_units)\n",
        "        self.dense  = Dense(self.tar_vocab_size , activation ='softmax')\n",
        "        \n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "        '''\n",
        "            One step decoder mechanisim step by step:\n",
        "        A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "        B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "        C. Concat the context vector with the step A output\n",
        "        D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "        E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "        F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "        '''\n",
        "        output_embedd =  self.embedding(input_to_decoder)                      # (batch_size , 1 , embedding_dim)\n",
        "        context_vector , attention_weights = self.attention(state_h , encoder_output)    # context_vector -> (batch_size , att_units)\n",
        "        concated_vector = tf.concat( [tf.expand_dims(context_vector , axis = 1)   , output_embedd ], axis = 2 )\n",
        "        dec_output ,state_h,state_c = self.lstm(concated_vector , initial_state = [state_h , state_c])       # dec_output ->  (batch_size , 1, dec_units)\n",
        "        output = tf.squeeze(self.dense(dec_output))\n",
        "\n",
        "        return output,state_h,state_c,attention_weights,context_vector\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV-x31rj6Hc4"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super(Decoder , self).__init__()\n",
        "      self.vocab_size = out_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "\n",
        "      self.onestepdecoder = OneStepDecoder(self.vocab_size, self.embedding_dim, self.input_length, self.dec_units ,self.score_fun ,self.att_units)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        # all_outputs = tf.TensorArray(tf.float32 , size=input_to_decoder.shape[1] , name = \"output_arrays\" )\n",
        "        all_outputs = tf.TensorArray(tf.float32 , size= 25 , name = \"output_arrays\" )\n",
        "\n",
        "\n",
        "        \n",
        "        #Iterate till the length of the decoder input\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "        # Return the tensor array\n",
        "        for  timestep in range(25):\n",
        "            output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector = self.onestepdecoder(input_to_decoder[: , timestep : timestep+1], encoder_output, decoder_hidden_state , decoder_cell_state)\n",
        "            all_outputs = all_outputs.write(timestep , output)\n",
        "        all_outputs = tf.transpose(all_outputs.stack() , [1,0,2])\n",
        "\n",
        "        \n",
        "        return all_outputs        # (batch_size,input_length,out_vocab_size)                   ;  input_length  -> decoder_inputs_length      \n",
        "        \n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfqBIe20MT3D"
      },
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self,encoder_inputs_length , decoder_inputs_length,score_fun):\n",
        "    #Intialize objects from encoder decoder\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(inp_vocab_size = vocab_size_ita ,embedding_size=100 , lstm_size = 100 , input_length = encoder_inputs_length )\n",
        "    self.decoder = Decoder(out_vocab_size = vocab_size_eng ,embedding_dim=100 , input_length = decoder_inputs_length , dec_units = 100 , score_fun = score_fun , att_units=100)# att_units is enc_units only\n",
        "\n",
        "  \n",
        "  def call(self,data):\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    # return the decoder output\n",
        "    enc_input , dec_input = data[0] , data[1]\n",
        "    enc_initial_states = self.encoder.initialize_states(1024)\n",
        "    enc_output , enc_state_h ,enc_state_c = self.encoder(enc_input , enc_initial_states)\n",
        "    dec_output =  self.decoder(dec_input , enc_output , enc_state_h , enc_state_c)\n",
        "\n",
        "    return dec_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY_3izrXMs8y"
      },
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QlbWAqNNlqe"
      },
      "source": [
        "<font color='blue'>**Training**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiuy33UMFlpO"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len_ita , max_len_eng):\n",
        "        self.encoder_inps = data['italian'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len_ita = max_len_ita\n",
        "        self.max_len_eng = max_len_eng\n",
        "\n",
        "    def __getitem__(self, i):                                         \n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len_ita, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len_eng, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len_eng, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])                 #  three things will be appended\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a1f8d9-745d-4adb-8b4e-f6db804ba8e6",
        "id": "gitoOkhsFlpP"
      },
      "source": [
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 22 , 25 )\n",
        "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 22, 25)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=1024)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=1024)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024, 22) (1024, 25) (1024, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWKg9okWFlpP"
      },
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model\n",
        "\n",
        "model_dot  = encoder_decoder(encoder_inputs_length=22,decoder_inputs_length=25 , score_fun = \"dot\")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model_dot.compile(optimizer=optimizer,loss= loss_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=4, verbose=0, mode='min'  ,restore_best_weights = True \n",
        ")\n",
        "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=2,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "log_dir=\"/content/logs/fit/model_dot\"         \n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)  \n",
        "\n",
        "callbacks = [reduceLR , earlystop , tensorboard_callback]\n"
      ],
      "metadata": {
        "id": "uxFzsl04FlpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "model_dot.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50, validation_data=test_dataloader, validation_steps=valid_steps , callbacks = callbacks)\n",
        "model_dot.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4e9943-0002-4728-be76-83d9f594fe69",
        "id": "5k5l8s81FlpQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "276/276 [==============================] - 186s 536ms/step - loss: 0.6675 - val_loss: 0.3876 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "276/276 [==============================] - 139s 503ms/step - loss: 0.3754 - val_loss: 0.3584 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.3507 - val_loss: 0.3359 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.3249 - val_loss: 0.3072 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.2971 - val_loss: 0.2829 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.2732 - val_loss: 0.2604 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.2516 - val_loss: 0.2410 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.2326 - val_loss: 0.2242 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.2161 - val_loss: 0.2096 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "276/276 [==============================] - 146s 528ms/step - loss: 0.2017 - val_loss: 0.1968 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.1889 - val_loss: 0.1859 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.1775 - val_loss: 0.1762 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.1673 - val_loss: 0.1676 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.1579 - val_loss: 0.1594 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.1492 - val_loss: 0.1521 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.1412 - val_loss: 0.1459 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "276/276 [==============================] - 146s 529ms/step - loss: 0.1337 - val_loss: 0.1394 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.1267 - val_loss: 0.1338 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.1201 - val_loss: 0.1289 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.1141 - val_loss: 0.1242 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.1084 - val_loss: 0.1200 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.1031 - val_loss: 0.1161 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.0982 - val_loss: 0.1123 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0936 - val_loss: 0.1095 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0893 - val_loss: 0.1060 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0853 - val_loss: 0.1035 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.0816 - val_loss: 0.1011 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.0781 - val_loss: 0.0991 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.0749 - val_loss: 0.0963 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.0718 - val_loss: 0.0950 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.0690 - val_loss: 0.0931 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.0663 - val_loss: 0.0916 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0638 - val_loss: 0.0900 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.0614 - val_loss: 0.0885 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0592 - val_loss: 0.0875 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.0572 - val_loss: 0.0860 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.0552 - val_loss: 0.0851 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.0534 - val_loss: 0.0840 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "276/276 [==============================] - 140s 507ms/step - loss: 0.0516 - val_loss: 0.0831 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.0499 - val_loss: 0.0823 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.0485 - val_loss: 0.0815 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.0469 - val_loss: 0.0812 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0456 - val_loss: 0.0802 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0443 - val_loss: 0.0797 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "276/276 [==============================] - 140s 506ms/step - loss: 0.0430 - val_loss: 0.0797 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "276/276 [==============================] - 140s 505ms/step - loss: 0.0419 - val_loss: 0.0793 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0407 - val_loss: 0.0788 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "276/276 [==============================] - 139s 505ms/step - loss: 0.0396 - val_loss: 0.0781 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.0387 - val_loss: 0.0782 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "276/276 [==============================] - 139s 504ms/step - loss: 0.0376 - val_loss: 0.0779 - lr: 0.0010\n",
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  2758000   \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  2750786   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,508,786\n",
            "Trainable params: 4,200,086\n",
            "Non-trainable params: 1,308,700\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dot.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRxfh83_od1P",
        "outputId": "aba6e7bf-3aec-4fae-d4fc-8a3f76c94cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  2758000   \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  2750786   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,508,786\n",
            "Trainable params: 4,200,086\n",
            "Non-trainable params: 1,308,700\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "#Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  sentence , predicted_sentence = sentence.split() , predicted_sentence.split()\n",
        "\n",
        "  attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')\n"
      ],
      "metadata": {
        "id": "wNosAO3O-rVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHWzAOQPvudj"
      },
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "            predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "            Save the attention weights\n",
        "            And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "    sequence_ita = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    sequence_ita = pad_sequences(sequence_ita, maxlen=22, dtype='int32', padding='post')\n",
        "    initial_states = model_dot.layers[0].initialize_states(1)               # batch_size , enc_units\n",
        "    # initial_states = tf.zeros([1 , 100]) , tf.zeros([1 , 100])              # batch_size , enc_units\n",
        "\n",
        "    enc_outputs,final_state_h , final_state_c =  model_dot.layers[0]( sequence_ita , initial_states)\n",
        "\n",
        "\n",
        "    input_dec = tknizer_eng.word_index['<start>']\n",
        "    word_index_end = tknizer_eng.word_index['<end>']\n",
        "    list_of_attention_weights =  tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
        "    predicted_sentence = \"\"\n",
        "    i=0\n",
        "\n",
        "    for i in range(25):\n",
        "        output , final_state_h , final_state_c , attention_weights , context_vector = model_dot.layers[1].onestepdecoder(tf.cast(tf.reshape(input_dec , [1,1]) , tf.int32) , enc_outputs , final_state_h , final_state_c)\n",
        "        # print(output.shape)                  # (13086,)\n",
        "        # print(final_state_h.shape)           # (1, 100)\n",
        "        # print(final_state_c.shape)           # (1, 100)\n",
        "        # print(attention_weights.shape)       # (1, 22, 1)\n",
        "        # print(tf.squeeze(attention_weights).shape)    # (22,)\n",
        "\n",
        "        list_of_attention_weights = list_of_attention_weights.write(i,tf.squeeze(attention_weights))\n",
        "        i+=1\n",
        "\n",
        "        input_dec = np.argmax(output)\n",
        "        if input_dec == word_index_end:\n",
        "            break\n",
        "\n",
        "        predicted_sentence += \" \" + tknizer_eng.index_word[input_dec]\n",
        "\n",
        "    plot_attention(list_of_attention_weights.stack() , input_sentence , predicted_sentence)\n",
        "    # print(list_of_attention_weights.stack().shape)\n",
        "\n",
        "    return predicted_sentence \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
        "ta = ta.write(0, tf.constant([1.0, 2.0]))\n",
        "ta = ta.write(1,  tf.constant([4.0, 23.0]))\n",
        "ta = ta.write(2,  tf.constant([19.0, 23.0]))\n",
        "\n",
        "print(ta.read(0))\n",
        "\n",
        "print(ta.read(1))\n",
        "\n",
        "print(ta.read(2))\n",
        "\n",
        "print(ta.stack())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468bc3cd-2f99-4b9f-fe2d-de17198b6ec8",
        "id": "3n-yDffpvudj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1. 2.], shape=(2,), dtype=float32)\n",
            "tf.Tensor([ 4. 23.], shape=(2,), dtype=float32)\n",
            "tf.Tensor([19. 23.], shape=(2,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.  2.]\n",
            " [ 4. 23.]\n",
            " [19. 23.]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('italian sentece------------' ,validation['italian'].iloc[0] )\n",
        "print('original english sentece---' , validation['english_inp'].iloc[0][8:])\n",
        "print('predicted english sentece--' , predict(validation['italian'].iloc[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "c744d0c7-d32d-4b43-d69e-6ce9942832a6",
        "id": "siMYZAuBvudk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "italian sentece------------ tom rimase a casa per tutto il giorno\n",
            "original english sentece--- tom stayed home all day\n",
            "predicted english sentece--  tom stayed home all day\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('italian sentece------------' ,validation['italian'].iloc[1] )\n",
        "print('original english sentece---' , validation['english_inp'].iloc[1][8:])\n",
        "print('predicted english sentece--' , predict(validation['italian'].iloc[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "vySNRpE3HaCz",
        "outputId": "6ba3c740-6aaf-4acd-c2c1-c9a7f5512944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "italian sentece------------ io dovevo dire qualcosa\n",
            "original english sentece--- i had to say something\n",
            "predicted english sentece--  i had to say something\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "italian_10 = validation.head(10)['italian']\n",
        "original_english_10 = validation.head(10)['english_out']\n",
        "predicted_sentence_10 = []\n",
        "\n",
        "for italian in italian_10:\n",
        "  predicted_sentence_10.append(predict(italian))\n",
        "\n",
        "result_10 = pd.DataFrame({'original' : original_english_10 , 'predicted' : predicted_sentence_10})\n",
        "result_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "611c5443-c7dc-49e8-f9ed-f76933ccc42e",
        "id": "wFvphWKEvudk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             original  \\\n",
              "144180                  tom stayed home all day <end>   \n",
              "120500                   i had to say something <end>   \n",
              "137797                  i want to get rid of it <end>   \n",
              "78480                      it is very hot today <end>   \n",
              "320129  he told his assistant that he would win <end>   \n",
              "218316            i am not one of your soldiers <end>   \n",
              "316039   i knew it would happen sooner or later <end>   \n",
              "106906                i would like to go faster <end>   \n",
              "317803   things are getting out of control here <end>   \n",
              "28335                          i am not worried <end>   \n",
              "\n",
              "                                               predicted  \n",
              "144180                           tom stayed home all day  \n",
              "120500                            i had to say something  \n",
              "137797                           i want to get rid of it  \n",
              "78480                            there is very hot today  \n",
              "320129   he acknowledged his assistant that he would win  \n",
              "218316                     i am not one of your soldiers  \n",
              "316039      i knew that would happen sooner later or now  \n",
              "106906                         i would like to go faster  \n",
              "317803               things are going out out of the way  \n",
              "28335                                   i am not worried  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6639fbb7-c816-4eaf-b506-d05577023548\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144180</th>\n",
              "      <td>tom stayed home all day &lt;end&gt;</td>\n",
              "      <td>tom stayed home all day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120500</th>\n",
              "      <td>i had to say something &lt;end&gt;</td>\n",
              "      <td>i had to say something</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137797</th>\n",
              "      <td>i want to get rid of it &lt;end&gt;</td>\n",
              "      <td>i want to get rid of it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78480</th>\n",
              "      <td>it is very hot today &lt;end&gt;</td>\n",
              "      <td>there is very hot today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320129</th>\n",
              "      <td>he told his assistant that he would win &lt;end&gt;</td>\n",
              "      <td>he acknowledged his assistant that he would win</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218316</th>\n",
              "      <td>i am not one of your soldiers &lt;end&gt;</td>\n",
              "      <td>i am not one of your soldiers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316039</th>\n",
              "      <td>i knew it would happen sooner or later &lt;end&gt;</td>\n",
              "      <td>i knew that would happen sooner later or now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106906</th>\n",
              "      <td>i would like to go faster &lt;end&gt;</td>\n",
              "      <td>i would like to go faster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317803</th>\n",
              "      <td>things are getting out of control here &lt;end&gt;</td>\n",
              "      <td>things are going out out of the way</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28335</th>\n",
              "      <td>i am not worried &lt;end&gt;</td>\n",
              "      <td>i am not worried</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6639fbb7-c816-4eaf-b506-d05577023548')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6639fbb7-c816-4eaf-b506-d05577023548 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6639fbb7-c816-4eaf-b506-d05577023548');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnmdQhVsvudk"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "import random\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "avg_score = 0 \n",
        "random_values = list(range(0,len(validation)))\n",
        "random.shuffle(random_values)\n",
        "\n",
        "for j in range(1000):\n",
        "  i = random_values[j]\n",
        "  eng_original = [validation['english_out'].iloc[i].split()[:-1] ]\n",
        "  italian_original = validation['italian'].iloc[i]\n",
        "  eng_predict = predict(italian_original).split()\n",
        "\n",
        "  # score_12gram = bleu.sentence_bleu(eng_original, eng_predict ,  weights=(0.5,0.5))        # since , sentences are small considering only 1-gram and 2-gram\n",
        "  score = bleu.sentence_bleu(eng_original, eng_predict ,  weights=(1.0,))     \n",
        "  avg_score += score   \n",
        "\n",
        "avg_score = avg_score/1000"
      ],
      "metadata": {
        "id": "W7wSjMRdvudk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_score"
      ],
      "metadata": {
        "id": "WuQkCZZlw25w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438a21d4-03a8-4688-ef8d-e4927b8ddad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7693846625844933"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymBJUvZdQKsC"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZlSQBdaSPlF"
      },
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model\n",
        "\n",
        "model_general  = encoder_decoder(encoder_inputs_length=22,decoder_inputs_length=25 , score_fun = \"general\")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model_general.compile(optimizer=optimizer,loss= loss_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "model_general.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50, validation_data=test_dataloader, validation_steps=valid_steps )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrLLdfTdojx-",
        "outputId": "93f4438a-66da-4fe3-a93e-510a07074fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "276/276 [==============================] - 189s 529ms/step - loss: 0.6753 - val_loss: 0.3900\n",
            "Epoch 2/50\n",
            "276/276 [==============================] - 136s 494ms/step - loss: 0.3763 - val_loss: 0.3561\n",
            "Epoch 3/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.3454 - val_loss: 0.3278\n",
            "Epoch 4/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.3177 - val_loss: 0.3013\n",
            "Epoch 5/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.2907 - val_loss: 0.2766\n",
            "Epoch 6/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.2665 - val_loss: 0.2544\n",
            "Epoch 7/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.2448 - val_loss: 0.2347\n",
            "Epoch 8/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.2247 - val_loss: 0.2166\n",
            "Epoch 9/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.2060 - val_loss: 0.1994\n",
            "Epoch 10/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.1885 - val_loss: 0.1843\n",
            "Epoch 11/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.1727 - val_loss: 0.1712\n",
            "Epoch 12/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.1588 - val_loss: 0.1594\n",
            "Epoch 13/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.1462 - val_loss: 0.1500\n",
            "Epoch 14/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.1350 - val_loss: 0.1394\n",
            "Epoch 15/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.1248 - val_loss: 0.1320\n",
            "Epoch 16/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.1155 - val_loss: 0.1250\n",
            "Epoch 17/50\n",
            "276/276 [==============================] - 137s 497ms/step - loss: 0.1071 - val_loss: 0.1176\n",
            "Epoch 18/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0996 - val_loss: 0.1121\n",
            "Epoch 19/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0929 - val_loss: 0.1074\n",
            "Epoch 20/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0870 - val_loss: 0.1033\n",
            "Epoch 21/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0817 - val_loss: 0.0981\n",
            "Epoch 22/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0768 - val_loss: 0.0972\n",
            "Epoch 23/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0725 - val_loss: 0.0932\n",
            "Epoch 24/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0686 - val_loss: 0.0903\n",
            "Epoch 25/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0652 - val_loss: 0.0868\n",
            "Epoch 26/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0620 - val_loss: 0.0870\n",
            "Epoch 27/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0591 - val_loss: 0.0846\n",
            "Epoch 28/50\n",
            "276/276 [==============================] - 137s 497ms/step - loss: 0.0564 - val_loss: 0.0826\n",
            "Epoch 29/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0540 - val_loss: 0.0801\n",
            "Epoch 30/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0519 - val_loss: 0.0796\n",
            "Epoch 31/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0497 - val_loss: 0.0774\n",
            "Epoch 32/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0478 - val_loss: 0.0763\n",
            "Epoch 33/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0462 - val_loss: 0.0753\n",
            "Epoch 34/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0444 - val_loss: 0.0743\n",
            "Epoch 35/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0429 - val_loss: 0.0736\n",
            "Epoch 36/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0416 - val_loss: 0.0726\n",
            "Epoch 37/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0402 - val_loss: 0.0726\n",
            "Epoch 38/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0388 - val_loss: 0.0707\n",
            "Epoch 39/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0378 - val_loss: 0.0701\n",
            "Epoch 40/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0367 - val_loss: 0.0692\n",
            "Epoch 41/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0358 - val_loss: 0.0688\n",
            "Epoch 42/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0346 - val_loss: 0.0692\n",
            "Epoch 43/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0337 - val_loss: 0.0674\n",
            "Epoch 44/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0328 - val_loss: 0.0675\n",
            "Epoch 45/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0320 - val_loss: 0.0675\n",
            "Epoch 46/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0312 - val_loss: 0.0667\n",
            "Epoch 47/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0305 - val_loss: 0.0674\n",
            "Epoch 48/50\n",
            "276/276 [==============================] - 137s 495ms/step - loss: 0.0298 - val_loss: 0.0693\n",
            "Epoch 49/50\n",
            "276/276 [==============================] - 137s 496ms/step - loss: 0.0292 - val_loss: 0.0682\n",
            "Epoch 50/50\n",
            "276/276 [==============================] - 138s 499ms/step - loss: 0.0285 - val_loss: 0.0667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d9ba4e510>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_general.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8vQp0rjQSzB",
        "outputId": "7edbb7ab-6c98-4d53-b598-acd941450157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  2758000   \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  2760886   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,518,886\n",
            "Trainable params: 4,210,186\n",
            "Non-trainable params: 1,308,700\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkEY7SsBMtrC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "#Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  sentence , predicted_sentence = sentence.split() , predicted_sentence.split()\n",
        "\n",
        "  attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP3kLZoPMvSu"
      },
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "            predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "            Save the attention weights\n",
        "            And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "    sequence_ita = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    sequence_ita = pad_sequences(sequence_ita, maxlen=22, dtype='int32', padding='post')\n",
        "    initial_states = model_general.layers[0].initialize_states(1)               # batch_size , enc_units\n",
        "    # initial_states = tf.zeros([1 , 100]) , tf.zeros([1 , 100])              # batch_size , enc_units\n",
        "\n",
        "    enc_outputs,final_state_h , final_state_c =  model_general.layers[0]( sequence_ita , initial_states)\n",
        "\n",
        "\n",
        "    input_dec = tknizer_eng.word_index['<start>']\n",
        "    word_index_end = tknizer_eng.word_index['<end>']\n",
        "    # list_of_attention_weights =  tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
        "    predicted_sentence = \"\"\n",
        "    i=0\n",
        "\n",
        "    for i in range(25):\n",
        "        output , final_state_h , final_state_c , attention_weights , context_vector = model_general.layers[1].onestepdecoder(tf.cast(tf.reshape(input_dec , [1,1]) , tf.int32) , enc_outputs , final_state_h , final_state_c)\n",
        "        # print(output.shape)                  # (13086,)\n",
        "        # print(final_state_h.shape)           # (1, 100)\n",
        "        # print(final_state_c.shape)           # (1, 100)\n",
        "        # print(attention_weights.shape)       # (1, 22, 1)\n",
        "        # print(tf.squeeze(attention_weights).shape)    # (22,)\n",
        "\n",
        "        # list_of_attention_weights = list_of_attention_weights.write(i,tf.squeeze(attention_weights))\n",
        "        i+=1\n",
        "\n",
        "        input_dec = np.argmax(output)\n",
        "        if input_dec == word_index_end:\n",
        "            break\n",
        "\n",
        "        predicted_sentence += \" \" + tknizer_eng.index_word[input_dec]\n",
        "\n",
        "    # plot_attention(list_of_attention_weights.stack() , input_sentence , predicted_sentence)\n",
        "    # print(list_of_attention_weights.stack().shape)\n",
        "\n",
        "    return predicted_sentence \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
        "ta = ta.write(0, tf.constant([1.0, 2.0]))\n",
        "ta = ta.write(1,  tf.constant([4.0, 23.0]))\n",
        "ta = ta.write(2,  tf.constant([19.0, 23.0]))\n",
        "\n",
        "print(ta.read(0))\n",
        "\n",
        "print(ta.read(1))\n",
        "\n",
        "print(ta.read(2))\n",
        "\n",
        "print(ta.stack())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZotc0gN9yYf",
        "outputId": "468bc3cd-2f99-4b9f-fe2d-de17198b6ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1. 2.], shape=(2,), dtype=float32)\n",
            "tf.Tensor([ 4. 23.], shape=(2,), dtype=float32)\n",
            "tf.Tensor([19. 23.], shape=(2,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.  2.]\n",
            " [ 4. 23.]\n",
            " [19. 23.]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('italian sentece------------' ,validation['italian'].iloc[0] )\n",
        "print('original english sentece---' , validation['english_inp'].iloc[0][8:])\n",
        "print('predicted english sentece--' , predict(validation['italian'].iloc[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "eCR8ltIQ3yTo",
        "outputId": "281177a3-4719-4b12-f0b3-c41a90b2fd5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "italian sentece------------ tom rimase a casa per tutto il giorno\n",
            "original english sentece--- tom stayed home all day\n",
            "predicted english sentece--  tom stayed at all at all day\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "italian_10 = validation.head(10)['italian']\n",
        "original_english_10 = validation.head(10)['english_out']\n",
        "predicted_sentence_10 = []\n",
        "\n",
        "for italian in italian_10:\n",
        "  predicted_sentence_10.append(predict(italian))\n",
        "\n",
        "result_10 = pd.DataFrame({'original' : original_english_10 , 'predicted' : predicted_sentence_10})\n",
        "result_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "foUDrzCw1Hjg",
        "outputId": "f72b89f5-f682-4d6c-e00b-5bf7e2242bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             original  \\\n",
              "144180                  tom stayed home all day <end>   \n",
              "120500                   i had to say something <end>   \n",
              "137797                  i want to get rid of it <end>   \n",
              "78480                      it is very hot today <end>   \n",
              "320129  he told his assistant that he would win <end>   \n",
              "218316            i am not one of your soldiers <end>   \n",
              "316039   i knew it would happen sooner or later <end>   \n",
              "106906                i would like to go faster <end>   \n",
              "317803   things are getting out of control here <end>   \n",
              "28335                          i am not worried <end>   \n",
              "\n",
              "                                              predicted  \n",
              "144180                     tom stayed at all at all day  \n",
              "120500                           i had to say something  \n",
              "137797                          i want to get rid of it  \n",
              "78480                                 today is very hot  \n",
              "320129          he said his assistant that he would win  \n",
              "218316                    i am not one of your soldiers  \n",
              "316039   i knew that would happen to the movie or later  \n",
              "106906                        i would like to go faster  \n",
              "317803           things are getting out of control here  \n",
              "28335                                  i am not worried  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c989e2fc-c2e3-4193-9dc1-bcded18036ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144180</th>\n",
              "      <td>tom stayed home all day &lt;end&gt;</td>\n",
              "      <td>tom stayed at all at all day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120500</th>\n",
              "      <td>i had to say something &lt;end&gt;</td>\n",
              "      <td>i had to say something</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137797</th>\n",
              "      <td>i want to get rid of it &lt;end&gt;</td>\n",
              "      <td>i want to get rid of it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78480</th>\n",
              "      <td>it is very hot today &lt;end&gt;</td>\n",
              "      <td>today is very hot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320129</th>\n",
              "      <td>he told his assistant that he would win &lt;end&gt;</td>\n",
              "      <td>he said his assistant that he would win</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218316</th>\n",
              "      <td>i am not one of your soldiers &lt;end&gt;</td>\n",
              "      <td>i am not one of your soldiers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316039</th>\n",
              "      <td>i knew it would happen sooner or later &lt;end&gt;</td>\n",
              "      <td>i knew that would happen to the movie or later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106906</th>\n",
              "      <td>i would like to go faster &lt;end&gt;</td>\n",
              "      <td>i would like to go faster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317803</th>\n",
              "      <td>things are getting out of control here &lt;end&gt;</td>\n",
              "      <td>things are getting out of control here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28335</th>\n",
              "      <td>i am not worried &lt;end&gt;</td>\n",
              "      <td>i am not worried</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c989e2fc-c2e3-4193-9dc1-bcded18036ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c989e2fc-c2e3-4193-9dc1-bcded18036ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c989e2fc-c2e3-4193-9dc1-bcded18036ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFwYeRlLtCYT",
        "outputId": "3c4d71b7-4c83-4bf5-d4b6-6613711191a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70767"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "import random\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "avg_score = 0 \n",
        "random_values = list(range(0,len(validation)))\n",
        "random.shuffle(random_values)\n",
        "\n",
        "for j in range(1000):\n",
        "  i = random_values[j]\n",
        "  eng_original = [validation['english_out'].iloc[i].split()[:-1] ]\n",
        "  italian_original = validation['italian'].iloc[i]\n",
        "  eng_predict = predict(italian_original).split()\n",
        "\n",
        "  # score_12gram = bleu.sentence_bleu(eng_original, eng_predict ,  weights=(0.5,0.5))        # since , sentences are small considering only 1-gram and 2-gram\n",
        "  score = bleu.sentence_bleu(eng_original, eng_predict ,  weights=(1.0,))     \n",
        "  avg_score += score   \n",
        "\n",
        "avg_score = avg_score/1000"
      ],
      "metadata": {
        "id": "VSd678HjHp3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYZdsuQUgoum",
        "outputId": "4bfb2535-f0f6-4136-b898-efad31c6b9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8018603438599083"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtyrYRA5vudh"
      },
      "source": [
        "model_concat  = encoder_decoder(encoder_inputs_length=22,decoder_inputs_length=25 , score_fun = \"concat\")\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model_concat.compile(optimizer=optimizer,loss= loss_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=4, verbose=0, mode='min'  ,restore_best_weights = True \n",
        ")\n",
        "callbacks = [earlystop ]"
      ],
      "metadata": {
        "id": "i8xmBUjhvudh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "model_concat.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50, validation_data=test_dataloader, validation_steps=valid_steps ,callbacks = callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43430c8-298c-4e2e-871e-28ce696a2b83",
        "id": "k0SFo209vudi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "276/276 [==============================] - 209s 595ms/step - loss: 0.6579 - val_loss: 0.3857\n",
            "Epoch 2/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.3736 - val_loss: 0.3564\n",
            "Epoch 3/50\n",
            "276/276 [==============================] - 152s 551ms/step - loss: 0.3488 - val_loss: 0.3335\n",
            "Epoch 4/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.3229 - val_loss: 0.3081\n",
            "Epoch 5/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.2972 - val_loss: 0.2829\n",
            "Epoch 6/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.2717 - val_loss: 0.2598\n",
            "Epoch 7/50\n",
            "276/276 [==============================] - 153s 553ms/step - loss: 0.2467 - val_loss: 0.2366\n",
            "Epoch 8/50\n",
            "276/276 [==============================] - 153s 553ms/step - loss: 0.2226 - val_loss: 0.2153\n",
            "Epoch 9/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.2011 - val_loss: 0.1970\n",
            "Epoch 10/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.1819 - val_loss: 0.1815\n",
            "Epoch 11/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.1649 - val_loss: 0.1684\n",
            "Epoch 12/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.1498 - val_loss: 0.1578\n",
            "Epoch 13/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.1365 - val_loss: 0.1486\n",
            "Epoch 14/50\n",
            "276/276 [==============================] - 152s 551ms/step - loss: 0.1249 - val_loss: 0.1396\n",
            "Epoch 15/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.1150 - val_loss: 0.1324\n",
            "Epoch 16/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.1064 - val_loss: 0.1244\n",
            "Epoch 17/50\n",
            "276/276 [==============================] - 153s 552ms/step - loss: 0.0988 - val_loss: 0.1209\n",
            "Epoch 18/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0922 - val_loss: 0.1171\n",
            "Epoch 19/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0864 - val_loss: 0.1133\n",
            "Epoch 20/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0812 - val_loss: 0.1096\n",
            "Epoch 21/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0766 - val_loss: 0.1113\n",
            "Epoch 22/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0725 - val_loss: 0.1038\n",
            "Epoch 23/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0687 - val_loss: 0.1010\n",
            "Epoch 24/50\n",
            "276/276 [==============================] - 153s 553ms/step - loss: 0.0653 - val_loss: 0.1007\n",
            "Epoch 25/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0621 - val_loss: 0.0967\n",
            "Epoch 26/50\n",
            "276/276 [==============================] - 153s 553ms/step - loss: 0.0594 - val_loss: 0.0967\n",
            "Epoch 27/50\n",
            "276/276 [==============================] - 153s 553ms/step - loss: 0.0568 - val_loss: 0.0937\n",
            "Epoch 28/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0544 - val_loss: 0.0943\n",
            "Epoch 29/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0523 - val_loss: 0.0916\n",
            "Epoch 30/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0503 - val_loss: 0.0899\n",
            "Epoch 31/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0485 - val_loss: 0.0903\n",
            "Epoch 32/50\n",
            "276/276 [==============================] - 152s 551ms/step - loss: 0.0467 - val_loss: 0.0904\n",
            "Epoch 33/50\n",
            "276/276 [==============================] - 153s 553ms/step - loss: 0.0450 - val_loss: 0.0850\n",
            "Epoch 34/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0435 - val_loss: 0.0876\n",
            "Epoch 35/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0421 - val_loss: 0.0853\n",
            "Epoch 36/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0409 - val_loss: 0.0844\n",
            "Epoch 37/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0396 - val_loss: 0.0854\n",
            "Epoch 38/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0384 - val_loss: 0.0824\n",
            "Epoch 39/50\n",
            "276/276 [==============================] - 153s 553ms/step - loss: 0.0373 - val_loss: 0.0814\n",
            "Epoch 40/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0364 - val_loss: 0.0812\n",
            "Epoch 41/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0355 - val_loss: 0.0805\n",
            "Epoch 42/50\n",
            "276/276 [==============================] - 157s 569ms/step - loss: 0.0346 - val_loss: 0.0813\n",
            "Epoch 43/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0336 - val_loss: 0.0795\n",
            "Epoch 44/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0330 - val_loss: 0.0848\n",
            "Epoch 45/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0322 - val_loss: 0.0787\n",
            "Epoch 46/50\n",
            "276/276 [==============================] - 153s 554ms/step - loss: 0.0313 - val_loss: 0.0799\n",
            "Epoch 47/50\n",
            "276/276 [==============================] - 153s 553ms/step - loss: 0.0306 - val_loss: 0.0793\n",
            "Epoch 48/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0299 - val_loss: 0.0833\n",
            "Epoch 49/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0292 - val_loss: 0.0777\n",
            "Epoch 50/50\n",
            "276/276 [==============================] - 152s 552ms/step - loss: 0.0287 - val_loss: 0.0779\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a35b7d790>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_concat.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b35710a2-f259-4078-da51-5e7378d02b7e",
        "id": "8NG32jdDvudi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_decoder_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_2 (Encoder)         multiple                  2758000   \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  2771087   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,529,087\n",
            "Trainable params: 4,220,387\n",
            "Non-trainable params: 1,308,700\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_concat.save('/content/model_concat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fLcsfx2vudi",
        "outputId": "82fb0e86-b56a-486e-8736-cb1c0ca02608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0a35b82890> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<__main__.Attention object at 0x7f0a35b9cbd0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0a35b9c150> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbAmdfeKPL8N",
        "outputId": "8806a1b0-96f0-48e6-e96c-1afd651c74ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/model_concat /content/gdrive/MyDrive"
      ],
      "metadata": {
        "id": "MrD0XVbgPG4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7evvB41SPlJ"
      },
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "    '''\n",
        "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "            predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "            Save the attention weights\n",
        "            And get the word using the tokenizer(word index) and then store it in a string.\n",
        "    E. Call plot_attention(#params)\n",
        "    F. Return the predicted sentence\n",
        "    '''\n",
        "    sequence_ita = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    sequence_ita = pad_sequences(sequence_ita, maxlen=22, dtype='int32', padding='post')\n",
        "    initial_states = model_concat.layers[0].initialize_states(1)               # batch_size , enc_units\n",
        "    # initial_states = tf.zeros([1 , 100]) , tf.zeros([1 , 100])              # batch_size , enc_units\n",
        "\n",
        "    enc_outputs,final_state_h , final_state_c =  model_concat.layers[0]( sequence_ita , initial_states)\n",
        "\n",
        "\n",
        "    input_dec = tknizer_eng.word_index['<start>']\n",
        "    word_index_end = tknizer_eng.word_index['<end>']\n",
        "    # list_of_attention_weights =  tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
        "    predicted_sentence = \"\"\n",
        "    i=0\n",
        "\n",
        "    for i in range(25):\n",
        "        output , final_state_h , final_state_c , attention_weights , context_vector = model_concat.layers[1].onestepdecoder(tf.cast(tf.reshape(input_dec , [1,1]) , tf.int32) , enc_outputs , final_state_h , final_state_c)\n",
        "        # print(output.shape)                  # (13086,)\n",
        "        # print(final_state_h.shape)           # (1, 100)\n",
        "        # print(final_state_c.shape)           # (1, 100)\n",
        "        # print(attention_weights.shape)       # (1, 22, 1)\n",
        "        # print(tf.squeeze(attention_weights).shape)    # (22,)\n",
        "\n",
        "        # list_of_attention_weights = list_of_attention_weights.write(i,tf.squeeze(attention_weights))\n",
        "        i+=1\n",
        "\n",
        "        input_dec = np.argmax(output)\n",
        "        if input_dec == word_index_end:\n",
        "            break\n",
        "\n",
        "        predicted_sentence += \" \" + tknizer_eng.index_word[input_dec]\n",
        "\n",
        "    # plot_attention(list_of_attention_weights.stack() , input_sentence , predicted_sentence)\n",
        "    # print(list_of_attention_weights.stack().shape)\n",
        "\n",
        "    return predicted_sentence \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
        "ta = ta.write(0, tf.constant([1.0, 2.0]))\n",
        "ta = ta.write(1,  tf.constant([4.0, 23.0]))\n",
        "ta = ta.write(2,  tf.constant([19.0, 23.0]))\n",
        "\n",
        "print(ta.read(0))\n",
        "\n",
        "print(ta.read(1))\n",
        "\n",
        "print(ta.read(2))\n",
        "\n",
        "print(ta.stack())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468bc3cd-2f99-4b9f-fe2d-de17198b6ec8",
        "id": "91c6MQzGSPlJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1. 2.], shape=(2,), dtype=float32)\n",
            "tf.Tensor([ 4. 23.], shape=(2,), dtype=float32)\n",
            "tf.Tensor([19. 23.], shape=(2,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.  2.]\n",
            " [ 4. 23.]\n",
            " [19. 23.]], shape=(3, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('italian sentece------------' ,validation['italian'].iloc[0] )\n",
        "print('original english sentece---' , validation['english_inp'].iloc[0][8:])\n",
        "print('predicted english sentece--' , predict(validation['italian'].iloc[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5630fc9-462c-4c04-dbac-21cb13a5f02a",
        "id": "3jOEBsGSSPlK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "italian sentece------------ tom rimase a casa per tutto il giorno\n",
            "original english sentece--- tom stayed home all day\n",
            "predicted english sentece--  tom stayed home for the moment day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "italian_10 = validation.head(10)['italian']\n",
        "original_english_10 = validation.head(10)['english_out']\n",
        "predicted_sentence_10 = []\n",
        "\n",
        "for italian in italian_10:\n",
        "  predicted_sentence_10.append(predict(italian))\n",
        "\n",
        "result_10 = pd.DataFrame({'original' : original_english_10 , 'predicted' : predicted_sentence_10})\n",
        "result_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "701e5b13-4f82-42db-98d5-cb7dad9e229f",
        "id": "FvCKDrW2SPlK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             original  \\\n",
              "144180                  tom stayed home all day <end>   \n",
              "120500                   i had to say something <end>   \n",
              "137797                  i want to get rid of it <end>   \n",
              "78480                      it is very hot today <end>   \n",
              "320129  he told his assistant that he would win <end>   \n",
              "218316            i am not one of your soldiers <end>   \n",
              "316039   i knew it would happen sooner or later <end>   \n",
              "106906                i would like to go faster <end>   \n",
              "317803   things are getting out of control here <end>   \n",
              "28335                          i am not worried <end>   \n",
              "\n",
              "                                       predicted  \n",
              "144180        tom stayed home for the moment day  \n",
              "120500                    i had to say something  \n",
              "137797                   i want to get rid of it  \n",
              "78480                         today is very warm  \n",
              "320129   he told his assistant that he would win  \n",
              "218316             i am not one of your soldiers  \n",
              "316039          i knew it would happen sooner or  \n",
              "106906                    i wish i to get faster  \n",
              "317803       things are going out of control out  \n",
              "28335                           i am not worried  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e11951d5-48a2-4417-bd2c-8893d0b1badd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>144180</th>\n",
              "      <td>tom stayed home all day &lt;end&gt;</td>\n",
              "      <td>tom stayed home for the moment day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120500</th>\n",
              "      <td>i had to say something &lt;end&gt;</td>\n",
              "      <td>i had to say something</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137797</th>\n",
              "      <td>i want to get rid of it &lt;end&gt;</td>\n",
              "      <td>i want to get rid of it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78480</th>\n",
              "      <td>it is very hot today &lt;end&gt;</td>\n",
              "      <td>today is very warm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320129</th>\n",
              "      <td>he told his assistant that he would win &lt;end&gt;</td>\n",
              "      <td>he told his assistant that he would win</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218316</th>\n",
              "      <td>i am not one of your soldiers &lt;end&gt;</td>\n",
              "      <td>i am not one of your soldiers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316039</th>\n",
              "      <td>i knew it would happen sooner or later &lt;end&gt;</td>\n",
              "      <td>i knew it would happen sooner or</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106906</th>\n",
              "      <td>i would like to go faster &lt;end&gt;</td>\n",
              "      <td>i wish i to get faster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317803</th>\n",
              "      <td>things are getting out of control here &lt;end&gt;</td>\n",
              "      <td>things are going out of control out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28335</th>\n",
              "      <td>i am not worried &lt;end&gt;</td>\n",
              "      <td>i am not worried</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e11951d5-48a2-4417-bd2c-8893d0b1badd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e11951d5-48a2-4417-bd2c-8893d0b1badd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e11951d5-48a2-4417-bd2c-8893d0b1badd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5EaFAmiSPlK"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "import random\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "avg_score = 0 \n",
        "random_values = list(range(0,len(validation)))\n",
        "random.shuffle(random_values)\n",
        "\n",
        "for j in range(1000):\n",
        "  i = random_values[j]\n",
        "  eng_original = [validation['english_out'].iloc[i].split()[:-1] ]\n",
        "  italian_original = validation['italian'].iloc[i]\n",
        "  eng_predict = predict(italian_original).split()\n",
        "\n",
        "  # score_12gram = bleu.sentence_bleu(eng_original, eng_predict ,  weights=(0.5,0.5))        # since , sentences are small considering only 1-gram and 2-gram\n",
        "  score = bleu.sentence_bleu(eng_original, eng_predict ,  weights=(1.0,))     \n",
        "  avg_score += score   \n",
        "\n",
        "avg_score = avg_score/1000"
      ],
      "metadata": {
        "id": "sTL99OFsSPlK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}